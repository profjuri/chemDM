#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SELFIES: a robust representation of semantically constrained graphs with an
    example application in chemistry (https://arxiv.org/abs/1905.13741)
    by Mario Krenn, Florian Haese, AkshatKuman Nigam, Pascal Friederich,
    Alan Aspuru-Guzik.

information:
    ML framework: pytorch
    chemistry framework: RDKit
"""

import os
import sys
import time

import numpy as np
import selfies as sf
import pandas as pd
import torch
import yaml
from rdkit import rdBase
from torch import nn
from torch.optim.lr_scheduler import ReduceLROnPlateau

from data_loader import \
    multiple_selfies_to_hot, multiple_smile_to_hot

rdBase.DisableLog('rdApp.error')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def _make_dir(directory):

    '''Makes the directory'''

    '''Arguments:
                    directory: directory path (str)'''
    os.makedirs(directory)


def save_models(encoder, decoder, epoch, optimizer_encoder, optimizer_decoder, settings, alphabet):

    '''This function saves the encoder and decoder parameters'''

    '''Arguments:
                    encoder: the encoder object (VAEEncoder object)
                    decoder: the decoder object (VAEDecoder object)
                    epoch: the current epoch (int)
                    settings: settings defined by the .yml file (dict)
                    alphabet: the alphabet generated by the function get_selfie_and_smiles_encodings_for_dataset (list)'''
    
    gru_stack_size = settings['encoder']['gru_stack_size']
    gru_neurons_num = settings['encoder']['gru_neurons_num']
    latent_dim = settings['encoder']['latent_dimension']
    save_path = settings['data']['save_path']


    out_dir = str(save_path) + 'stack_size' + str(gru_stack_size)  + 'neurons_num' + str(gru_neurons_num) + '_l_dim' + str(latent_dim) + '/{}'.format(epoch) 
    _make_dir(out_dir)

    #torch.save(encoder, '{}/E'.format(out_dir))
    #torch.save(decoder, '{}/D'.format(out_dir))
    
    torch.save(encoder.state_dict(), '{}/E.pt'.format(out_dir))
    torch.save(decoder.state_dict(), '{}/D.pt'.format(out_dir))

    settings_folder = str(save_path) + 'stack_size' + str(gru_stack_size)  + 'neurons_num' + str(gru_neurons_num) + '_l_dim' + str(latent_dim) + '/settings'

    log_folder = settings_folder
    log_filename = 'settings.yml'

    if not os.path.exists(settings_folder):
        os.makedirs(settings_folder)

        log_filepath = os.path.join(log_folder, log_filename)
        data = {**settings, 'alphabet': alphabet}

        with open(log_filepath, 'w') as file:
            yaml.dump(data, file)


def save_models_epoch_loss(epoch, loss, recon_loss, val_loss, kld_loss, lr_new_enc, KLD, settings):

    '''This function saves the epoch, total training loss, trainin reconstruction loss, training kld loss and the total validation loss to a .txt file'''

    '''Arguments:
                    epoch: the epoch currently being saved (int)
                    loss: the total training loss (float)
                    recon_loss: the training reconstruction loss (float)
                    val_loss: the total validation loss (float)
                    kld_loss: the training kld loss (float)
                    settings: settings defined by the .yml file (dict)'''
    
    gru_stack_size = settings['encoder']['gru_stack_size']
    gru_neurons_num = settings['encoder']['gru_neurons_num']
    latent_dim = settings['encoder']['latent_dimension']
    save_path = settings['data']['save_path']



    out_dir = str(save_path) + 'stack_size' + str(gru_stack_size)  + 'neurons_num' + str(gru_neurons_num) + '_l_dim' + str(latent_dim) + '/settings'

    log_folder = out_dir  # Replace with the desired folder path
    log_filename = 'epoch_loss.txt'

    log_filepath = os.path.join(log_folder, log_filename)

    # Create the log folder if it doesn't exist
    if not os.path.exists(log_folder):
        os.makedirs(log_folder)

    file_exists = os.path.isfile(log_filepath)
    ratio = recon_loss/kld_loss
    
    with open(log_filepath, 'a') as file:
        if not file_exists:
            file.write("epoch,loss,recon_loss,kld_loss,ratio,val_loss\n")
        file.write(f'{epoch},{loss},{recon_loss},{kld_loss},{ratio},{val_loss}\n')


class VAEEncoder(nn.Module):

    def __init__(self, in_dimension, gru_stack_size, gru_neurons_num,
                 latent_dimension):

        '''Recurrent layers to encode molecule to latent space'''

        '''Arguments:
                        in_dimension: the number of elements in each one hot array (int)
                        gru_stack_size: the number of gru_stacks (int)
                        gru_neurons_num: the number of neurons (int)
                        latent_dimension: the size of the latent space (int)'''
        
        super(VAEEncoder, self).__init__()
        self.latent_dimension = latent_dimension
        self.gru_stack_size = gru_stack_size
        self.gru_neurons_num = gru_neurons_num

        # RNN Encoder
        self.encode_RNN = nn.GRU(
            input_size=in_dimension,
            hidden_size=gru_neurons_num,
            num_layers=gru_stack_size,
            batch_first=False)

        self.encode_FC_mu = nn.Sequential(
            nn.Linear(gru_neurons_num, latent_dimension),
        )

        self.encode_FC_log_var = nn.Sequential(
            nn.Linear(gru_neurons_num, latent_dimension),
        )

    @staticmethod
    def reparameterize(mu, log_var):

        '''Reparameterization trick'''

        '''Arguments:
                        mu: the mean latent vector (Pytorch float tensor)
                        log_var: the natural logarithm of the variance tensor of each latent vector (Pytorch float tensor)'''
        
        '''Outputs:
                        z: a latent vector modified by some distribution defined by the standard deviation (Pytorch float tensor)'''

        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return eps.mul(std).add_(mu)

    def forward(self, x, hidden=None):

        '''Pass through the Encoder RNN'''

        '''Arguments:
                        x: The feed forward object, i.e., the transformed one hot vector (Pytorch float tensor)'''
        
        '''Outputs:
                        z: a latent vector modified by some distribution defined by the standard deviation (Pytorch float tensor)
                        mu: the mean latent vector (Pytorch float tensor)
                        log_var: the natural logarithm of the variance tensor of each latent vector (Pytorch float tensor)'''


        if hidden is None:
            hidden = self.init_hidden(x.size(1))  # Initialize hidden state based on batch size

        # Encode using RNN
        rnn_output, hidden = self.encode_RNN(x, hidden)
        rnn_output_last = rnn_output[-1, :, :]  # Consider the last RNN output

        # Latent space mean
        mu = self.encode_FC_mu(rnn_output_last)

        # Latent space variance
        log_var = self.encode_FC_log_var(rnn_output_last)

        # Reparameterize
        z = self.reparameterize(mu, log_var)
        return z, mu, log_var

    def init_hidden(self, batch_size=1):
                
        '''Hidden layer initalisation'''

        weight = next(self.parameters())
        return weight.new_zeros(self.gru_stack_size, batch_size,
                                self.gru_neurons_num)


class VAEDecoder(nn.Module):

    def __init__(self, latent_dimension, gru_stack_size, gru_neurons_num,
                 out_dimension):
        
        '''Recurrent layers to decode latent vectors to one hot vectors'''

        '''Arguments:
                        latent_dimension: the size of the latent space (int)
                        gru_stack_size: the number of gru layers (Int)
                        gru_neurons_num: the number of neurons in each layer (int)
                        out_dimension: the length of the selfies_alphabet (int)'''
        

        super(VAEDecoder, self).__init__()
        self.latent_dimension = latent_dimension
        self.gru_stack_size = gru_stack_size
        self.gru_neurons_num = gru_neurons_num

        # Simple Decoder
        self.decode_RNN = nn.GRU(
            input_size=latent_dimension,
            hidden_size=gru_neurons_num,
            num_layers=gru_stack_size,
            batch_first=False)

        self.decode_FC = nn.Sequential(
            nn.Linear(gru_neurons_num, out_dimension),
        )

    def init_hidden(self, batch_size=1):

        '''Initalises the hidden layer'''

        weight = next(self.parameters())
        return weight.new_zeros(self.gru_stack_size, batch_size,
                                self.gru_neurons_num)

    def forward(self, z, hidden):

        '''A forward pass throught the entire model.'''

        '''Arguments:
                        z: the latent vector (Pytorch float tensor)
                        hidden: the hidden layer/s (Pytorch float tensor)'''
        
        '''Outputs:
                        decoded: the decoded output, should be a one hot vector (Pytorch float tensor)
                        hidden: the output hidden layer (Pytorch float tensor)'''


        # Decode
        l1, hidden = self.decode_RNN(z, hidden)
        decoded = self.decode_FC(l1)  # fully connected layer

        return decoded, hidden


def train_model(vae_encoder, vae_decoder, data_train, data_valid ,num_epochs, batch_size,
                lr_enc, lr_dec, KLD_alpha,
                sample_num, sample_len, alphabet, settings):
    
    '''Train the Variational Auto-Encoder'''

    '''Arguments:
                    vae_encoder: the encoder object (VAEEncoder object)
                    vae_decoder: the decoder object (VAEDecoder object)
                    data_train: the training one hot vector set of the molecules (Pytorch float tensor)
                    data_valid: the validation one hot vector set of the molecules (Pytorch float tensor)
                    num_epochs: the desired number of epochs (int)
                    batch_size: the batch size (int)
                    lr_enc: the learning rate for the encoder training (float)
                    lr_dec: the learning rate for the decoder training (float)
                    KLD_alpha: the weight you apply to the KLD term (float)
                    alphabet: the alphabet generated by the function get_selfie_and_smiles_encodings_for_dataset (list)
                    settings: settings defined by the yml file (dict)''' 


    # initialize an instance of the model
    

    optimizer_encoder = torch.optim.Adam(vae_encoder.parameters(), lr=lr_enc)
    optimizer_decoder = torch.optim.Adam(vae_decoder.parameters(), lr=lr_dec)
    scheduler = ReduceLROnPlateau(optimizer_encoder, mode='min', factor=0.5, patience=10, verbose=True)
    scheduler2 = ReduceLROnPlateau(optimizer_decoder, mode='min', factor=0.5, patience=10, verbose=True)

    data_train = data_train.clone().detach().to('cpu')
    data_valid = data_valid.clone().detach().to('cpu')

    num_batches_train = int(len(data_train) / batch_size)
    num_batches_valid = int(len(data_valid) / batch_size)



    for epoch in range(num_epochs):
        start = time.time()
        for batch_iteration in range(num_batches_train):  # batch iterator


            # manual batch iterations
            start_idx = batch_iteration * batch_size
            stop_idx = (batch_iteration + 1) * batch_size
            batch = data_train[start_idx: stop_idx].to(device)

            # reshaping for efficient parallelization
            inp_flat_one_hot = batch.flatten(start_dim=1)
            inp_flat_one_hot = inp_flat_one_hot.unsqueeze(0).to(device)

            latent_points, mus, log_vars = vae_encoder(inp_flat_one_hot)
            latent_points = latent_points.unsqueeze(0)

            hidden = vae_decoder.init_hidden(batch_size=batch_size)

            out_one_hot = torch.zeros_like(batch, device=device)
            for seq_index in range(batch.shape[1]):
                out_one_hot_line, hidden = vae_decoder(latent_points, hidden)
                out_one_hot[:, seq_index, :] = out_one_hot_line[0]


            
            loss, recon_loss, kld_loss = compute_elbo(batch, out_one_hot, mus, log_vars, KLD_alpha) ##switched the out_one_hot and the batch variables around
            loss = loss 

            optimizer_encoder.zero_grad()
            optimizer_decoder.zero_grad()
            loss.backward(retain_graph=True)
            
            nn.utils.clip_grad_norm_(vae_decoder.parameters(), 10.0)
            optimizer_encoder.step()
            optimizer_decoder.step()

            if batch_iteration % 30 ==0:
                print('Batch:', batch_iteration, '/', num_batches_train, 'loss:', loss.item())


        scheduler.step(loss)
        scheduler2.step(loss)


        if epoch % 50 == 0:
            save_models(vae_encoder, vae_decoder, epoch, optimizer_encoder, optimizer_decoder, settings, alphabet)
            

        vae_encoder.eval()
        vae_decoder.eval()
        one_hot_tensor = torch.empty(0, dtype=torch.float32).to('cpu')

        with torch.no_grad():
            for batch_iteration in range(num_batches_valid):  # batch iterator

                start_idx = batch_iteration * batch_size
                stop_idx = (batch_iteration + 1) * batch_size
                batch = data_valid[start_idx: stop_idx].to(device)

        
                inp_flat_one_hot = batch.flatten(start_dim=1).to(device)
                inp_flat_one_hot = inp_flat_one_hot.unsqueeze(0)
                latent_points, mus, log_vars = vae_encoder(inp_flat_one_hot)
                latent_points = latent_points.unsqueeze(0)
                hidden = vae_decoder.init_hidden(batch_size=batch.shape[0])

                out_one_hot = torch.zeros_like(batch, device=device)
                for seq_index in range(batch.shape[1]):
                    out_one_hot_line, hidden = vae_decoder(latent_points, hidden)
                    out_one_hot[:, seq_index, :] = out_one_hot_line[0]
                one_hot_tensor = torch.cat((one_hot_tensor, out_one_hot.to('cpu')))

        vae_encoder.train()
        vae_decoder.train()

        val_loss = validation_loss(data_valid, one_hot_tensor, settings)

        save_models_epoch_loss(epoch, loss.item(), recon_loss, val_loss.item(), kld_loss, lr_enc, KLD_alpha, settings)




def compute_elbo(x, x_hat, mus, log_vars, KLD_alpha):

    '''Compute the total loss of the VAE (encoder and decoder are defined by one shared loss)'''

    '''Arguments:
                    x: the batch/ the one hot vector object defined by the batch size (Pytorch float tensor)
                    x_hat: the one hot vector object after it has been fed through the encoder and decoder (Pytorch float tensor)
                    mus: the mean latent vector object (Pytorch float tensor)
                    log_vars: the natural logarithm of the variance tensor of each latent vector (Pytorch float tensor)
                    KLD_alpha: the weight you apply to the KLD term (Pytorch float tensor)'''
    
    '''Outputs:
                    total_loss: the total training loss (Pytorch float tensor)
                    recon_loss: the reconstruciton training loss (Pytorch float tensor)
                    KLD loss: the KLD training loss (Pytorch float tensor)'''


    inp = x_hat.reshape(-1, x_hat.shape[2])
    target = x.reshape(-1, x.shape[2]).argmax(1)

    criterion = torch.nn.CrossEntropyLoss()
    recon_loss = criterion(inp, target)
    kld = -0.5 * torch.mean(1. + log_vars - mus.pow(2) - log_vars.exp())
    ratio = recon_loss/(KLD_alpha * kld)



    total_loss = recon_loss + (KLD_alpha * kld) 


    return total_loss, recon_loss, KLD_alpha * kld

def validation_loss(x, x_hat, settings):

    '''Gives the reconstruction loss of the validation set'''

    '''Arguments:
                    x: the batch/ the one hot vector object defined by the batch size (Pytorch float tensor)
                    x_hat: the one hot vector object after it has been fed through the encoder and decoder (Pytorch float tensor)
                    settings: settings...'''

    '''Outputs:
                    recon_loss: the validation reconstruct loss (Pytorch float tensor)'''
    
    batch_size = settings['data']['batch_size']
    num_batches_train = int(x.shape[0] / batch_size)
    recon_loss = torch.tensor([0]).to(device)



    for batch_iteration in range(num_batches_train):  # batch iterator


        start_idx = batch_iteration * batch_size
        stop_idx = (batch_iteration + 1) * batch_size
        sub_x = x[start_idx: stop_idx].to(device)
        sub_x_hat = x_hat[start_idx: stop_idx].to(device)


        inp = sub_x_hat.reshape(-1, x_hat.shape[2])
        target = sub_x.reshape(-1, x.shape[2]).argmax(1)
        criterion = torch.nn.CrossEntropyLoss()
        sub_loss = criterion(inp, target)
        recon_loss = recon_loss + sub_loss
    

    return recon_loss/num_batches_train


def get_selfie_and_smiles_encodings_for_dataset(file_path, settings):

    '''Returns encoding, alphabet and length of largest molecule in SMILES and SELFIES, given a file containing SMILES molecules.'''

    '''Arguments:
                    file_path: .csv file with molecules. Column name containing the smiles must be 'smiles' (str)'''
    
    '''Outputs:
                    selfies_list: the SELFIES encoding of the SMILES molecules provided (list)
                    selfies_alphabet: the alphabet of the SELFIES encoding (list)
                    largest_selfies_len: the longest SELFIES encoding length (int)
                    smiles_list: a list of the SMILES encodings (list)
                    smiles_alphabet: the alphabet of the SMILES encoding (list)
                    largest_smiles_len: the longest SMILES encoding length (int)'''
                    

    file_type = settings['data']['file_type']

    if file_type == '.csv' or file_type =='.txt':
        df = pd.read_csv(file_path)
        df = df.dropna()
    elif file_type == '.h5':
        df = pd.read_hdf(file_path)
        df = df.dropna()

    new_constraints = sf.get_semantic_constraints()
    new_constraints['N'] = 5
    new_constraints['B'] = 4






    sf.set_semantic_constraints(new_constraints)  # update constraints


    smiles_list = np.asanyarray(df.smiles)

    smiles_list = remove_unrecognized_symbols(smiles_list)

    smiles_alphabet = list(set(''.join(smiles_list)))
    smiles_alphabet.append(' ')  # for padding

    largest_smiles_len = len(max(smiles_list, key=len))

    print('--> Translating SMILES to SELFIES...')
    selfies_list = list(map(sf.encoder, smiles_list))

    

    all_selfies_symbols = sf.get_alphabet_from_selfies(selfies_list)
    selfies_alphabet = list(all_selfies_symbols)
    selfies_alphabet.insert(0, '[nop]')
    selfies_alphabet.insert(1, '.')

    largest_selfies_len = max(sf.len_selfies(s) for s in selfies_list)

    print('Finished translating SMILES to SELFIES.')

    return selfies_list, selfies_alphabet, largest_selfies_len, \
           smiles_list, smiles_alphabet, largest_smiles_len



def remove_unrecognized_symbols(smiles_list):

    '''Removes blank spaces from the SMILES encodings'''

    '''Arguments:
                    smiles_list: the list of SMILES encodings (list)'''
    
    '''Outputs:
                    cleaned_smiles: the cleaned SMILES encodings list (list)'''

    cleaned_smiles = [smiles.replace('\n', '') for smiles in smiles_list]

    return cleaned_smiles

def data_init(settings, device):

    '''Data initialisation'''

    '''Arguments:
                    settings: settings defined by the corresponding .yml file (dict)
                    device: the device being used to store data (str)'''
    
    '''Outputs:
                    data_train: the training one hot vector set (Pytorch float tensor)
                    data_valid: the validation one hot vector set (Pytorch float tensor)
                    len_max_molec: the maximum length of the molecule encodings (int)
                    len_alphabet: the length of the alphabet used (int)
                    len_max_mol_one_hot: the length of the maximum one hot representation (int)
                    encoding_alphabet: the alphabet used (list)'''

    file_name_smiles = settings['data']['smiles_file']
    full_alphabet_set = set(settings['data']['full_alphabet_set'])
    torch_seed = settings['data']['torch_seed']

    


    encoding_list, encoding_alphabet, largest_molecule_len, _, _, _ = \
        get_selfie_and_smiles_encodings_for_dataset(file_name_smiles, settings)
        
    for letter in full_alphabet_set:
        if letter not in encoding_alphabet:
            encoding_alphabet.append(letter)

    data = multiple_selfies_to_hot(encoding_list, largest_molecule_len, encoding_alphabet)

    len_max_molec = data.shape[1]
    len_alphabet = data.shape[2]
    len_max_mol_one_hot = len_max_molec * len_alphabet


    torch.manual_seed(torch_seed)
    
    data = torch.tensor(data, dtype=torch.float).to('cpu')
    rand_perms = torch.randperm(data.size()[0])
    data = data[rand_perms]

    train_valid_test_size = [0.8, 0.2, 0.0]

    idx_train_val = int(len(data) * train_valid_test_size[0])
    idx_val_test = idx_train_val + int(len(data) * train_valid_test_size[1])

    data_train = data[0:idx_train_val]
    data_valid = data[idx_train_val:idx_val_test]

    return data_train, data_valid, len_max_molec, len_alphabet, len_max_mol_one_hot, encoding_alphabet


def main():
    if os.path.exists("selfies_rnn.yml"):
        settings = yaml.safe_load(open("selfies_rnn.yml", "r"))
    else:
        print("Expected a file settings.yml but didn't find it.")
        return

    data_parameters = settings['data']
    batch_size = data_parameters['batch_size']
    encoder_parameter = settings['encoder']
    decoder_parameter = settings['decoder']
    training_parameters = settings['training']
    


    torch.cuda.empty_cache()
    data_train, data_valid, len_max_molec, len_alphabet, len_max_mol_one_hot, encoding_alphabet = data_init(settings, device)
    vae_encoder = VAEEncoder(in_dimension=len_max_mol_one_hot, **encoder_parameter).to(device)
    vae_decoder = VAEDecoder(**decoder_parameter, out_dimension=len_alphabet).to(device)


    print("start training")
    train_model(**training_parameters,
                vae_encoder=vae_encoder,
                vae_decoder=vae_decoder,
                batch_size=batch_size,
                data_train=data_train,
                data_valid=data_valid,
                alphabet=encoding_alphabet,
                sample_len=len_max_molec,
                settings=settings 
                )



if __name__ == '__main__':
    try:
        main()
    except AttributeError:
        _, error_message, _ = sys.exc_info()
        print(error_message)
