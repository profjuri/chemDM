{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import chemistry_vae_selfies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/PropsQM9/listprops.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Translating SMILES to SELFIES...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished translating SMILES to SELFIES.\n",
      "selfies aplhabet: ['[=Branch2]', '[#Branch1]', '[Ring2]', '[=C]', '[nop]', '[Branch2]', '[#C]', '[#Branch2]', '[Ring1]', '[N]', '[=N]', '[=Branch1]', '[C]', '[F]', '[Branch1]', '[#N]', '[O]', '[=O]']\n",
      "smiles aplhabet: ['N', '#', 'C', '(', 'F', '=', 'O', '3', '5', '2', '1', '4', ')', ' ']\n"
     ]
    }
   ],
   "source": [
    "# here we want to read in data and tranform them into one_hot\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "folder_path = \"./datasets/\"\n",
    "file_name = \"SelectedSMILES_QM9.txt\"\n",
    "\n",
    "full_path = folder_path + file_name\n",
    "\n",
    "selfies_list, selfies_alphabet, largest_selfies_len, smiles_list, smiles_alphabet, largest_smiles_len = chemistry_vae_selfies.get_selfie_and_smiles_encodings_for_dataset(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_alphabet = ['[#Branch2]', '[Ring2]', '[Branch2]', '[=Branch2]', '[O]', '[=O]', '[=C]', '[=N]', '[#Branch1]', '[=Branch1]', '[nop]', '[N]', '[Branch1]', '[F]', '[#C]', '[#N]', '[Ring1]', '[C]']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define source file location\n",
    "file_to_load =  \"./saved_models_RNN/\"\n",
    "# training file name encoder\n",
    "training_file_nameE = \"300/E\"\n",
    "# training file name decoder\n",
    "training_file_nameD = \"300/D\"\n",
    "# load data\n",
    "#load_data_trained = file_to_load + training_file_nameE\n",
    "# Alphabet has 18 letters, largest molecule is 21 letters. (build this as an output function later ... )\n",
    "largest_selfies_len_dataset = largest_selfies_len\n",
    "largest_smiles_len_dataset = largest_smiles_len\n",
    "\n",
    "#in_dimension = len(selfies_alphabet)*largest_selfies_len\n",
    "in_dimension = len(smiles_alphabet)*largest_smiles_len\n",
    "\n",
    "\n",
    "\n",
    "# load the trained encoder\n",
    "vae_encoder = torch.load(file_to_load + training_file_nameE) #, map_location=torch.device(device=\"cpu\"))\n",
    "#print(vae_encoder)\n",
    "\n",
    "# load the trained decoder\n",
    "vae_decoder = torch.load(file_to_load + training_file_nameD) #, map_location=torch.device(device=\"cpu\"))\n",
    "#print(vae_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_latent_space_vector(largest_selfies_len,selfies_alphabet_in):\n",
    "\n",
    "    # Random input tensor for tests\n",
    "    in_dimension_input = largest_selfies_len*len(selfies_alphabet_in)\n",
    "    x = torch.randn(in_dimension_input).unsqueeze(0)\n",
    "\n",
    "    z =set()\n",
    "    vae_encoder.eval()\n",
    "    vae_decoder.eval()\n",
    "    z, mu, log_var = vae_encoder(x)\n",
    "\n",
    "    return z.unsqueeze(0), mu, log_var.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, mu, log_var = create_random_latent_space_vector(largest_selfies_len, selfies_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_var = []\n",
    "list_var.append(log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-7.1405, -5.7359, -8.3026, -8.4360, -7.7541, -7.6566, -7.2899,\n",
      "          -7.0162, -8.5449, -7.1038, -8.4080, -9.1792, -8.8428, -8.0314,\n",
      "          -8.9814, -8.9128, -7.1589, -9.4305, -8.6080, -8.2441, -8.9749,\n",
      "          -8.1896, -8.2922, -7.6497, -9.4049]]], grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_var\n",
    "\n",
    "log_vars_valid = [item[0].detach().squeeze(0) for item in log_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-7.1405, -5.7359, -8.3026, -8.4360, -7.7541, -7.6566, -7.2899, -7.0162,\n",
       "         -8.5449, -7.1038, -8.4080, -9.1792, -8.8428, -8.0314, -8.9814, -8.9128,\n",
       "         -7.1589, -9.4305, -8.6080, -8.2441, -8.9749, -8.1896, -8.2922, -7.6497,\n",
       "         -9.4049])]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_vars_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.9237e-04, 3.2280e-03, 2.4786e-04, 2.1691e-04, 4.2899e-04, 4.7290e-04,\n",
      "        6.8243e-04, 8.9722e-04, 1.9453e-04, 8.2197e-04, 2.2307e-04, 1.0316e-04,\n",
      "        1.4441e-04, 3.2510e-04, 1.2572e-04, 1.3466e-04, 7.7793e-04, 8.0242e-05,\n",
      "        1.8264e-04, 2.6281e-04, 1.2655e-04, 2.7753e-04, 2.5047e-04, 4.7621e-04,\n",
      "        8.2319e-05])\n"
     ]
    }
   ],
   "source": [
    "log_var2 = (math.e**(log_vars_valid)[0])\n",
    "\n",
    "print(log_var2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_vars_valid = (log_var2 - log_var2[(log_var2).argmin()]) / (log_var2[(log_var2).argmax()] - log_var2[(log_var2).argmin()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_var_rep_train = log_vars_valid[:train_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2262, 1.0000, 0.0533, 0.0434, 0.1108, 0.1247, 0.1913, 0.2595, 0.0363,\n",
       "        0.2356, 0.0454, 0.0073, 0.0204, 0.0778, 0.0144, 0.0173, 0.2216, 0.0000,\n",
       "        0.0325, 0.0580, 0.0147, 0.0627, 0.0541, 0.1258])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_var_rep_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4010, 1.0000, 0.1418, 0.1206, 0.2456, 0.2672, 0.3587, 0.4387, 0.1043,\n",
      "         0.4119, 0.1249, 0.0251, 0.0639, 0.1896, 0.0471, 0.0553, 0.3956, 0.0000,\n",
      "         0.0952, 0.1516, 0.0479, 0.1609, 0.1435, 0.2688, 0.0024]])\n"
     ]
    }
   ],
   "source": [
    "print(log_vars_valid.view(-1, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1361,  3.0508, -2.4523,  0.1599,  0.3531,  3.7195, -2.4395,\n",
      "          -1.0487, -3.2625,  1.3347,  1.1850, -2.5649, -1.6585, -0.7064,\n",
      "          -5.1830,  0.4643, -2.2288, -0.5731,  0.4159,  1.6115,  1.2580,\n",
      "          -0.4602,  0.0360,  0.2228, -0.1765]]], grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[-0.1324,  3.0267, -2.4508,  0.1601,  0.3412,  3.7247, -2.4426, -1.0520,\n",
      "         -3.2546,  1.3301,  1.1906, -2.5673, -1.6571, -0.6978, -5.1796,  0.4702,\n",
      "         -2.2226, -0.5762,  0.4121,  1.6035,  1.2590, -0.4442,  0.0348,  0.2295,\n",
      "         -0.1722]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0123, 0.0256, 0.0041, 0.0050, 0.0077, 0.0072, 0.0116, 0.0048, 0.0040,\n",
      "         0.0094, 0.0040, 0.0048, 0.0045, 0.0052, 0.0027, 0.0045, 0.0060, 0.0035,\n",
      "         0.0044, 0.0057, 0.0047, 0.0086, 0.0043, 0.0056, 0.0036]],\n",
      "       grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00495631781580328"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "log_var2 = (math.e**log_var)\n",
    "\n",
    "print(z)\n",
    "print(mu)\n",
    "print(log_var2)\n",
    "\n",
    "\n",
    "\n",
    "(math.e**float(log_var[0][3]))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0256, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0027, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(log_var2[0][(log_var2).argmax()])\n",
    "print(log_var2[0][(log_var2).argmin()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_variance = (log_var2 - log_var2[0][(log_var2).argmin()]) / (log_var2[0][(log_var2).argmax()] - log_var2[0][(log_var2).argmin()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalised_variance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-6ba087d7c304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalised_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'normalised_variance' is not defined"
     ]
    }
   ],
   "source": [
    "print(normalised_variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
