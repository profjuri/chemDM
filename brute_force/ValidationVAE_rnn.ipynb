{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chemistry_vae_symmetric_rnn\n",
    "import data_loader\n",
    "import selfies\n",
    "import torch\n",
    "import importlib\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pysmiles import read_smiles\n",
    "import Levenshtein\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'F': 1, 'Cl': 1, 'Br': 1, 'I': 1, 'B': 3, 'B+1': 2, 'B-1': 4, 'O': 2, 'O+1': 3, 'O-1': 1, 'N': 3, 'N+1': 4, 'N-1': 2, 'C': 4, 'C+1': 5, 'C-1': 3, 'P': 5, 'P+1': 6, 'P-1': 4, 'S': 6, 'S+1': 7, 'S-1': 5, '?': 8}\n",
      "                                                  smiles  energy_gap\n",
      "0      COC1=C(C(OC1=O)c1ccccc1Cl)C(C)=NN=C(C)C1=C(OC)...     0.20713\n",
      "1      CN1N(c2ccccc2)C(=O)C(=C1C)N=Cc1ccccc1C=NC1=C(C...     0.21467\n",
      "2                   COc1cc(OC)c(C=CC(=O)c2ccccn2)c(OC)c1     0.21389\n",
      "3            O=P1(c2ccccc2)c2ccc3ccccc3c2c2c3ccccc3ccc12     0.20755\n",
      "4              COc1cc(Br)cc(C=NNC(=O)CC2=CNc3ccccc23)c1O     0.22060\n",
      "...                                                  ...         ...\n",
      "34405  C[NH+]1CCC23C4CCC(OS(=O)(=O)[O-])C2Oc2c(OC(C)=...     0.17994\n",
      "34406                      [NH3+]C(C1CC1C(=O)[O-])C(O)=O     0.15398\n",
      "34407                      [NH3+]C(C1CC1C(=O)[O-])C(O)=O     0.18568\n",
      "34408  CSC1=NC2=C(NC(C(C(CC(=O)c3ccccc3)c3ccccc3)C(=N...     0.11361\n",
      "34409  CC(CCC(=C)C(C)C(O)=O)C1CCC2C3=C(C(=O)CC12C)C1(...     0.13363\n",
      "\n",
      "[34410 rows x 2 columns]\n",
      "--> Translating SMILES to SELFIES...\n",
      "Finished translating SMILES to SELFIES.\n"
     ]
    }
   ],
   "source": [
    "# here we want to read in data and tranform them into one_hot\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "folder_path = \"../../Clean_VAE_file/datasets/\"\n",
    "file_name = \"CSD_EES_DB_energies.csv\"\n",
    "\n",
    "full_path = folder_path + file_name\n",
    "\n",
    "selfies_list, selfies_alphabet, largest_selfies_len, smiles_list, smiles_alphabet, largest_smiles_len = chemistry_vae_symmetric_rnn.get_selfie_and_smiles_encodings_for_dataset(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define source file location\n",
    "file_to_load =  \"../../rnn_sym_crystals/stack_size3neurons_num2150/\"\n",
    "#file_to_load =  \"./model runs/saved_models_run1/\"\n",
    "#file_to_load =  \"./saved_models_run1/\"\n",
    "# training file name encoder\n",
    "training_file_nameE = \"500/E\"\n",
    "# training file name decoder\n",
    "training_file_nameD = \"500/D\"\n",
    "# load data\n",
    "#load_data_trained = file_to_load + training_file_nameE\n",
    "# Alphabet has 18 letters, largest molecule is 21 letters. (build this as an output function later ... )\n",
    "largest_selfies_len_dataset = largest_selfies_len\n",
    "largest_smiles_len_dataset = largest_smiles_len\n",
    "\n",
    "#in_dimension = len(selfies_alphabet)*largest_selfies_len\n",
    "in_dimension = len(smiles_alphabet)*largest_smiles_len\n",
    "\n",
    "\n",
    "\n",
    "# load the trained encoder\n",
    "vae_encoder = torch.load(file_to_load + training_file_nameE, map_location=torch.device(device=\"cpu\"))\n",
    "#print(vae_encoder)\n",
    "\n",
    "# load the trained decoder\n",
    "vae_decoder = torch.load(file_to_load + training_file_nameD, map_location=torch.device(device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_alphabet = [\n",
    "    \"[nop]\",\n",
    "    \"[Cl]\",\n",
    "    \"[=As]\",\n",
    "    \"[=Branch2]\",\n",
    "    \"[NH2+1]\",\n",
    "    \"[#Branch1]\",\n",
    "    \"[C]\",\n",
    "    \"[Branch1]\",\n",
    "    \"[=Se]\",\n",
    "    \"[S+1]\",\n",
    "    \"[=N-1]\",\n",
    "    \"[=C]\",\n",
    "    \"[S]\",\n",
    "    \"[C-1]\",\n",
    "    \"[=N]\",\n",
    "    \"[#Branch2]\",\n",
    "    \"[#N]\",\n",
    "    \"[=Branch1]\",\n",
    "    \"[N+1]\",\n",
    "    \"[I]\",\n",
    "    \"[NH1+1]\",\n",
    "    \"[Br]\",\n",
    "    \"[=NH1+1]\",\n",
    "    \"[O-1]\",\n",
    "    \"[=P]\",\n",
    "    \"[P-1]\",\n",
    "    \"[=O+1]\",\n",
    "    \"[SiH1]\",\n",
    "    \"[B-1]\",\n",
    "    \"[=O]\",\n",
    "    \"[#C]\",\n",
    "    \"[As]\",\n",
    "    \"[Se-1]\",\n",
    "    \"[Ring2]\",\n",
    "    \"[F]\",\n",
    "    \"[=N+1]\",\n",
    "    \"[=Ring2]\",\n",
    "    \"[=B-1]\",\n",
    "    \"[N-1]\",\n",
    "    \"[=S]\",\n",
    "    \"[NH3+1]\",\n",
    "    \"[Ring1]\",\n",
    "    \"[Branch2]\",\n",
    "    \"[=Ring1]\",\n",
    "    \"[P+1]\",\n",
    "    \"[=NH2+1]\",\n",
    "    \"[S-1]\",\n",
    "    \"[N]\",\n",
    "    \"[O]\",\n",
    "    \"[P]\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions\n",
    "\n",
    "def translate_selfie(sequence):  \n",
    "        SELFIESGenerated = ''\n",
    "\n",
    "        for i in range(len(sequence)):\n",
    "                SELFIESGenerated = SELFIESGenerated + selfies_alphabet[sequence[i]]\n",
    "        return SELFIESGenerated\n",
    "\n",
    "def translate_smile(sequence):  \n",
    "\n",
    "        SELFIESGenerated = \"\"\n",
    "\n",
    "        for i in range(len(sequence)):\n",
    "                SELFIESGenerated = SELFIESGenerated + smiles_alphabet[sequence[i]]\n",
    "        return SELFIESGenerated\n",
    "        \n",
    "def create_onehot_instance(selfie_input,largest_selfies_len,selfies_alphabet_in):\n",
    "\n",
    "    inttest_hot, arraytest_hot = data_loader.selfies_to_hot(selfie_input,largest_selfies_len, selfies_alphabet_in)\n",
    "    x = torch.from_numpy(arraytest_hot).flatten().float().unsqueeze(0)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def create_latent_space_vector(selfie_input,largest_selfies_len,selfies_alphabet_in):\n",
    "\n",
    "    x = create_onehot_instance(selfie_input,largest_selfies_len,selfies_alphabet_in)\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    z =set()\n",
    "    vae_encoder.eval()\n",
    "    vae_decoder.eval()\n",
    "    z, mu, log_var = vae_encoder(x)\n",
    "\n",
    "    return mu.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def decode_from_latentspace(latent_point_in, largest_selfies_len_in, selfies_alphabet_len, method):\n",
    "\n",
    "\n",
    "        vae_decoder.eval()\n",
    "        vae_encoder.eval()\n",
    "\n",
    "        sequence = []\n",
    "\n",
    "        hidden = vae_decoder.init_hidden(batch_size=1)\n",
    "\n",
    "         \n",
    "        for seq_index in range(largest_selfies_len_in):\n",
    "                out_one_hot_line, hidden = vae_decoder(latent_point_in, hidden)\n",
    "\n",
    "                if method == 0:\n",
    "                        sequence.append(out_one_hot_line.argmax())\n",
    "\n",
    "                elif method ==1:\n",
    "                        # Apply softmax and sample from the distribution to get the next token\n",
    "                        softmax = torch.nn.Softmax(dim=2)\n",
    "                        probabilities = softmax(out_one_hot_line)\n",
    "                        categorical_dist = dist.Categorical(probabilities)\n",
    "                        sample = categorical_dist.sample()\n",
    "                        sequence.append(sample)\n",
    "\n",
    "                else:\n",
    "                        print(\"method is 0 for argmax or 1 for stat sampling\")\n",
    "        \n",
    "        \n",
    "\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELFIES input: NC1=CC=CC=C1C#CC2=CC=CC=C2C#CC3=CC=C(C=C3)C#CC4=CC=CC=C4C#CC5=CC=CC=C5N\n"
     ]
    }
   ],
   "source": [
    "#Â pick a molecule\n",
    "\n",
    "selfie_input = selfies_list[200]\n",
    "print('SELFIES input:', selfies.decoder(selfie_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded in NC1=CC=CC=C1C#CC2=CC=CC=C2C#CC3=CC=C(C=C3)C#CC4=CC=CC=C4C#CC5=CC=CC=C5N\n",
      "reconstructed out NC1=CC=CC=C1C#CC2=CC=CC=C2C#CC3=CC=C(C=C3)C#CC4=CC=CC=C4C#CC5=CC=CC=C5N\n",
      "reconstructed out NC1=CC=CC=C1C#CC2=CC=CC=C2C#CC3=CC=C(C=C3)C#CC4=CC=CC=C4C#CC5=CC=CC=C5N\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-74cf3c6f4636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcoded_selfie_from_latent_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_from_latentspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_latent_space_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselfie_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlargest_selfies_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselfies_alphabet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlargest_selfies_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselfies_alphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mselfie_from_latent_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_selfie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoded_selfie_from_latent_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reconstructed out\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselfies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselfie_from_latent_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-26250ea853e7>\u001b[0m in \u001b[0;36mdecode_from_latentspace\u001b[0;34m(latent_point_in, largest_selfies_len_in, selfies_alphabet_len, method)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlargest_selfies_len_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mout_one_hot_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_point_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DM_chems/VAE_sandbox/brute_force/chemistry_vae_symmetric_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, hidden)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_FC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fully connected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"encoded in\", selfies.decoder(selfie_input))\n",
    "\n",
    "for i in range(10):\n",
    "    coded_selfie_from_latent_space = decode_from_latentspace(create_latent_space_vector(selfie_input,largest_selfies_len,selfies_alphabet) , largest_selfies_len, len(selfies_alphabet),0) \n",
    "    selfie_from_latent_space = translate_selfie(coded_selfie_from_latent_space)\n",
    "    print(\"reconstructed out\", selfies.decoder(selfie_from_latent_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "step: 10\n",
      "step: 20\n",
      "step: 30\n",
      "step: 40\n",
      "step: 50\n",
      "step: 60\n",
      "step: 70\n",
      "step: 80\n",
      "step: 90\n"
     ]
    }
   ],
   "source": [
    "##qm9 levenshtein:\n",
    "\n",
    "smiles_input = []\n",
    "recon_smiles = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    ran_int = random.randint(0, len(selfies_list))\n",
    "\n",
    "    inp_self = selfies_list[ran_int]\n",
    "    smiles_input.append(selfies.decoder(inp_self))\n",
    "\n",
    "    \n",
    "    latent_vector = create_latent_space_vector(inp_self,largest_selfies_len,selfies_alphabet)\n",
    "    coded_selfie_from_latent_space = decode_from_latentspace(latent_vector, largest_selfies_len, len(selfies_alphabet),0) \n",
    "    selfie_from_latent_space = translate_selfie(coded_selfie_from_latent_space)\n",
    "    recon_smiles.append(selfies.decoder(selfie_from_latent_space))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print('step:', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean Levenshtein distance: 17.2 +/- 18.46889276594566\n"
     ]
    }
   ],
   "source": [
    "levenshteins = []\n",
    "\n",
    "for i in range(len(smiles_input)):\n",
    "    original_smiles = smiles_input[i]\n",
    "    output_smiles = recon_smiles[i]\n",
    "\n",
    "    # Calculate the Levenshtein distance\n",
    "    levenshtein_distance = Levenshtein.distance(original_smiles, output_smiles)\n",
    "    levenshteins.append(levenshtein_distance)\n",
    "\n",
    "\n",
    "print('mean Levenshtein distance:', np.mean(levenshteins), '+/-', np.std(levenshteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
