#!/usr/bin/python3

import torch
import os
import sys
import yaml
import pandas as pd
from torch.nn.utils.rnn import pad_sequence
import time

import mlp
import vae
from functions import get_selfie_and_smiles_encodings_for_dataset
from functions_sub import selfies_to_all, lpoints_to_sequences, sequences_to_lpoints, try_encode, get_run_log_list, save_index, unique_values_and_first_indices, non_none_values_and_indices, generate_normal_tensor, sequences_to_smiles
from function_fingerprints import gen_fingerprints_BF


from rdkit import Chem
from rdkit.Chem import rdFingerprintGenerator
from rdkit.Chem import RDConfig
from rdkit.Chem import AllChem
import deepchem as dc 
sys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))
import sascorer

from rdkit import RDLogger 
RDLogger.DisableLog('rdApp.*') 

torch.set_grad_enabled(False)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


#pd.options.mode.chained_assignment = None



def get_models(settings):

    '''Gets the models and other items needed to run the algorithm'''

    '''Arguments:
                        settings: dict of settings used (dict)'''
        
    '''Outputs:
                        vae_encoder: the encoder object (VAEEncoder object)
                        vae_decoder: the decoder object (VAEDecoder object) 
                        mlp_model: the multi-layered perceptron object, trained on mus (PropertyRegressionModel object)
                        z_model: the multi-layered perceptron object, trained on zs (PropertyRegressionModel object)
                        encoding_alphabet: the alphabet generated by the function get_selfie_and_smiles_encodings_for_dataset (list)
                        largest_molecule_len: the maximum length of the molecule encodings (int)
                        lpoint_size: size of the normal tensor (shape[1]), should correspond to the size of the latent vecotrs you want to apply this to (int)
                        FP_size: size of the daylight and morgan fingerprints (int)'''

    vae_save_path = settings['vae']['save_path']
    vae_epoch = settings['vae']['epoch']
    vae_settings = yaml.safe_load(open(str(vae_save_path) + "settings/" + "settings.yml", "r"))
    encoder_parameter = vae_settings['encoder']
    decoder_parameter = vae_settings['decoder']
    encoding_alphabet = vae_settings['alphabet']



    encoder_dict_path = str(vae_save_path) + str(vae_epoch) + "/E.pt"
    decoder_dict_path = str(vae_save_path) + str(vae_epoch) + "/D.pt"
    encoder_dict = torch.load(encoder_dict_path, map_location = device)
    decoder_dict = torch.load(decoder_dict_path, map_location = device)

    largest_molecule_len = int(encoder_dict['encode_RNN.weight_ih_l0'].shape[1]/len(encoding_alphabet))
    lpoint_size = decoder_dict['decode_RNN.weight_ih_l0'].shape[1]


    vae_encoder = vae.VAEEncoder(in_dimension=(encoder_dict['encode_RNN.weight_ih_l0'].shape[1]), **encoder_parameter)
    vae_decoder = vae.VAEDecoder(**decoder_parameter, out_dimension=len(encoding_alphabet), seq_len=largest_molecule_len)
    vae_encoder.load_state_dict(encoder_dict)
    vae_decoder.load_state_dict(decoder_dict)
    mlp_model, FP_size = load_mlp(settings)



    vae_encoder.eval()
    vae_decoder.eval()
    mlp_model.eval()

    vae_encoder.to(device)
    vae_decoder.to(device)
    mlp_model.to(device)


    return vae_encoder, vae_decoder, mlp_model, encoding_alphabet, largest_molecule_len, lpoint_size, FP_size


def load_mlp(settings):

    '''Function to load the MLP'''

    '''Arguments:
                        settings: dict of settings used (dict)'''
        
    '''Outputs:
                        mlp_model: the multi-layered perceptron object, trained on mus and fingerprints (PropertyRegressionModel object)
                        FP_size: size of the daylight and morgan fingerprints (int)'''


    mlp_save_path = settings['MLP']['save_path']
    mlp_epoch = settings['MLP']['epoch']

    mlp_settings = yaml.safe_load(open(str(mlp_save_path) + "settings/" + "settings.yml", "r"))
    mlp_model = mlp.PropertyRegressionModel(mlp_settings)
    state_dict = torch.load(mlp_save_path + '/' + str(mlp_epoch) + '/model.pt', map_location=device)
    mlp_model.load_state_dict(state_dict)

    mlp_model.eval()
    mlp_model.to(device)

    FP_size = mlp_save_path['model_params']['FP_size']


    return mlp_model, FP_size

def gen_step(encoding_list, smiles_index, encoding_alphabet, largest_molecule_len, vae_encoder, z_num, eps):

    '''Brute force step 1. Generates the Zs'''

    '''Arguments:
                        encoding_list: a list containing the SELFIES (list)
                        smiles_index: specific SMILES index we are looking at, e.g., 0 for the 1st SMILES in the seed list (int)
                        encoding_alphabet: the alphabet generated by the function get_selfie_and_smiles_encodings_for_dataset (list)
                        largest_molecule_len: the maximum length of the molecule encodings (int)
                        vae_encoder: the encoder object (VAEEncoder object)
                        z_num: number of zs you want, e.g., 10 will give you 10 Zs in the output (int)
                        eps: the final normal distributed tensor (Pytorch float.32 tensor)'''
        
    '''Outputs:
                        zs: latent vectors defined by the distribution in eps and the mus (Pytorch float.32 tensor)'''


    _, mu, log_var = selfies_to_all([encoding_list[smiles_index]], encoding_alphabet, largest_molecule_len, vae_encoder)
    std = torch.exp(0.5 * log_var)
    std_repeat = std.squeeze().repeat(z_num, 1)
    del std
    mus_repeat = mu.squeeze().repeat(z_num, 1)
    del mu
    zs = eps.mul(std_repeat).add_(mus_repeat).to(device)
            
    del std_repeat
    del mus_repeat
    del log_var

    return zs

def z_process_step(zs, encoding_alphabet, vae_decoder, vae_encoder):

    ''''Brute force step 2. Removes non unique Zs and converts them to mus and SMILES'''

    '''Arguments:
                        zs: latent vectors defined by the distribution in eps and the mus (Pytorch float.32 tensor)
                        encoding_alphabet: the alphabet generated by the function get_selfie_and_smiles_encodings_for_dataset (list)
                        vae_decoder: the decoder object (VAEDecoder object) 
                        vae_encoder: the encoder object (VAEEncoder object)'''
        
    '''Outputs:
                        mus: the mean latent vectors (Pytorch float.32 tensor) (Pytorch float.32 tensor)
                        sm_list: the list of SMILES encodings (list)'''


    scattered_seq_tensor = lpoints_to_sequences(zs, vae_decoder)
    mus = sequences_to_lpoints(scattered_seq_tensor, encoding_alphabet, vae_encoder)
    _, sm_list = sequences_to_smiles(scattered_seq_tensor.cpu(), encoding_alphabet)

    return mus, sm_list


def sanitisation_step(scattered_smiles, mus, condition):

    '''Brute force step 3. Sanitises outputted SMILES and makes sure they are valid'''

    '''Arguments:
                        scattered_smiles: the list of SMILES encodings from previous steps (list)
                        mus: the mean latent vectors (Pytorch float.32 tensor)
                        condition: condition that checks whether a character is in the SELFIES alphabet (lambda function)'''
        
    '''Outputs:
                        top_mols: list of RDKit mol objects that survived the sanitisation (list)
                        mus: the mean latent vectors which have survived sanitisation (Pytorch float.32 tensor)'''



    original_indices = list(range(len(scattered_smiles)))
    scattered_mols = [Chem.MolFromSmiles(x) for x in scattered_smiles]

    scattered_mols, non_none_indices = non_none_values_and_indices(scattered_mols)
    scattered_smiles = [scattered_smiles[x] for x in non_none_indices]
    original_indices = [original_indices[x] for x in non_none_indices]

    canon_list = [Chem.MolToSmiles(x, canonical=True) for x in scattered_mols]
    _, first_indices = unique_values_and_first_indices(canon_list)
    scattered_smiles = [scattered_smiles[x] for x in first_indices]
    scattered_mols = [scattered_mols[x] for x in first_indices]
    original_indices = [original_indices[x] for x in first_indices]


    try_encode_list = [try_encode(x) for x in scattered_smiles]
    scatterd_selfies, non_none_indices = non_none_values_and_indices(try_encode_list)

    scattered_mols = [scattered_mols[x] for x in non_none_indices]
    original_indices = [original_indices[x] for x in non_none_indices]
    del non_none_indices


    top_selfies_index = [x for x in range(len(scatterd_selfies)) if all(condition(element) for element in scatterd_selfies[x][1:-1].split("]["))]
    top_mols = [scattered_mols[x] for x in top_selfies_index]
    final_indices = [original_indices[x] for x in top_selfies_index]

    mus = mus[final_indices]

    del scattered_smiles
    del scattered_mols
    del scatterd_selfies
    del top_selfies_index
    del original_indices
    del final_indices
    del canon_list
    del first_indices


    return top_mols, mus


def gen_predictions_step(MLP_model, m2v_tensor, mfp_tensor, dfp_tensor, mus):

    '''Brute force step 4. Predicts the molecular properties of valid molecules outputted from the VAE here'''

    '''Arguments:
                        MLP_model: the multi-layered perceptron object, trained on mus (PropertyRegressionModel object)
                        m2v_tensor: pytorch tensor containing mol2vec fingerprints (Pytorch float.32 tensor)
                        mfp_tensor: pytorch tensor containing morgan fingerprints (Pytorch float.32 tensor)
                        dfp_tensor: pytorch tensor containing daylight fingerprints (Pytorch float.32 tensor)
                        mus: the mean latent vectors (Pytorch float.32 tensor)'''
        
    '''Outputs:
                        predictions: pytorch tensor of shape [X, N] where X is the number of mols and N is the number of properties. Contains predictions of molecular properties (Pytorch float.32 tensor)
                        ID1_indices: pytorch tensor containing the indices of molecules which fit the ideal_mols criteria (Pytorch float.32 tensor)
                        ID2_indices: pytorch tensor containing the indices of molecules which fit the ideal_mols_2 criteria (Pytorch float.32 tensor)'''

    batch_size = 16384
    num_batches = int(len(mus) // batch_size) + 1
    prediction_list = []


    for x in range(num_batches):
        start_idx =x * batch_size
        stop_idx = (x+1) * batch_size

        m2v_batch = m2v_tensor[start_idx:stop_idx].to(device)
        mfp_batch = mfp_tensor[start_idx:stop_idx].to(device)
        dfp_batch = dfp_tensor[start_idx:stop_idx].to(device)
        mus_batch = mus[start_idx:stop_idx].to(device)

        predictions = MLP_model(m2v_batch, mfp_batch, dfp_batch,mus_batch).squeeze().to('cpu')
        predictions[:, 1::2] = (10**(predictions[:, 1::2])) / predictions[:, ::2]
        prediction_list.append(predictions)
    
    del m2v_batch
    del mfp_batch
    del dfp_batch
    del mus_batch
    
    predictions = torch.cat(prediction_list)

    threshold_1 = (predictions[:, 0] < 2.5) & (predictions[:, 1] > 0.05)
    threshold_2 = (predictions[:, 2] < 2.5) & (predictions[:, 3] > 0.05)

    ID1_threshold = threshold_1
    ID2_threshold = threshold_1 + threshold_2

    ID1_indices = torch.nonzero(ID1_threshold).squeeze()
    ID2_indices = torch.nonzero(ID2_threshold).squeeze()

    return predictions, ID1_indices, ID2_indices


def save_CSVs_step(mols, predictions, ID1_indices, ID2_indices, smiles_index, settings):

    '''Brute force step 5. Here is where the ideal_mols and ideal_mols_2 csvs are generated.'''

    '''Arguments:
                        mols: list of RDKit mol objects (list)
                        predictions: pytorch tensor of shape [X, N] where X is the number of mols and N is the number of properties. Contains predictions of molecular properties (Pytorch float.32 tensor)
                        ID1_indices: pytorch tensor containing the indices of molecules which fit the ideal_mols criteria (Pytorch float.32 tensor)
                        ID2_indices: pytorch tensor containing the indices of molecules which fit the ideal_mols_2 criteria (Pytorch float.32 tensor)
                        smiles_index: index of the current SMILES seed (int)
                        settings: settings defined by the corresponding .yml file (dict)'''
        

    predictions_ID1 = predictions[ID1_indices]
    predictions_ID2 = predictions[ID2_indices]

    if len(predictions_ID1) > 0:

        if ID1_indices.dim() < 1:
            mols_ID1 = mols[ID1_indices]
            dE1_1 = [predictions_ID1[0].item()]
            OS1_1 = [predictions_ID1[1].item()]
            dE2_1 = [predictions_ID1[2].item()]
            OS2_1 = [predictions_ID1[3].item()]
            ID1_canon = Chem.MolToSmiles(mols_ID1, canonical=True)
        else:
            mols_ID1 = [mols[x] for x in ID1_indices]
            dE1_1 = [predictions_ID1[x, 0].item() for x in range(predictions_ID1.shape[0])]
            OS1_1 = [predictions_ID1[x, 1].item() for x in range(predictions_ID1.shape[0])]
            dE2_1 = [predictions_ID1[x, 2].item() for x in range(predictions_ID1.shape[0])]
            OS2_1 = [predictions_ID1[x, 3].item() for x in range(predictions_ID1.shape[0])]
            ID1_canon = [Chem.MolToSmiles(x, canonical=True) for x in mols_ID1]

        df_ID1 = pd.DataFrame({'canon_smiles': ID1_canon,
                        'TransitionEnergies1': dE1_1,
                        'OscillatorStrength1': OS1_1,
                        'TransitionEnergies2': dE2_1,
                        'OscillatorStrength2': OS2_1,
                        'smiles_index': smiles_index})

        dump_csvs(df_ID1, settings, 1)

    

    if ID2_indices.dim() < 1:

        dE1_2 = [predictions_ID2[0].item()]
        OS1_2 = [predictions_ID2[1].item()]
        dE2_2 = [predictions_ID2[2].item()]
        OS2_2 = [predictions_ID2[3].item()]
        mols_ID2 = mols[ID2_indices]
        ID2_canon = Chem.MolToSmiles(mols_ID2, canonical=True)

        df_ID2 = pd.DataFrame({'canon_smiles': ID2_canon,
                        'TransitionEnergies1': dE1_2,
                        'OscillatorStrength1': OS1_2,
                        'TransitionEnergies2': dE2_2,
                        'OscillatorStrength2': OS2_2,
                        'smiles_index': smiles_index})
    
    
        dump_csvs(df_ID2, settings, 2)

    else:

        dE1_2 = [predictions_ID2[x, 0].item() for x in range(predictions_ID2.shape[0])]
        OS1_2 = [predictions_ID2[x, 1].item() for x in range(predictions_ID2.shape[0])]
        dE2_2 = [predictions_ID2[x, 2].item() for x in range(predictions_ID2.shape[0])]
        OS2_2 = [predictions_ID2[x, 3].item() for x in range(predictions_ID2.shape[0])]

        mols_ID2 = [mols[x] for x in ID2_indices]
        ID2_canon = [Chem.MolToSmiles(x, canonical=True) for x in mols_ID2]

        df_ID2 = pd.DataFrame({'canon_smiles': ID2_canon,
                        'TransitionEnergies1': dE1_2,
                        'OscillatorStrength1': OS1_2,
                        'TransitionEnergies2': dE2_2,
                        'OscillatorStrength2': OS2_2,
                        'smiles_index': smiles_index})
    
        dump_csvs(df_ID2, settings, 2)




def dump_csvs(df, settings, file_type):

    '''Function to dump 2 different csvs, ideal_mols, ideal_mols_2'''

    '''Arguments:
                        df: pandas DataFrame we want to dump (pandas DataFrame object)
                        settings: settings defined by the corresponding .yml file (dict)
                        file_type: 1, or 2. Corresponds to the file name we want (int)'''



    if file_type ==1:
        loc_file = '/ideal_mols.csv'
    if file_type ==2:
        loc_file = '/ideal_mols_2.csv'
   

    save_path = settings['data']['save_path']
    csv_file_path = save_path + loc_file

    if not os.path.exists(save_path):
        os.makedirs(save_path)

    if not os.path.exists(csv_file_path):
        df.to_csv(csv_file_path, mode='a', header=True, index=False)
    else:
        df.to_csv(csv_file_path, mode='a', header=False, index=False)





def bf(vae_encoder, vae_decoder, MLP_model, encoding_alphabet, largest_molecule_len, lpoint_size, encoding_list, FP_size, settings):

    '''Brute force algorithm - NETWORK A. Takes a list of molecular seeds and outputs a bunch of molecules that fit our criteria.'''

    '''Arguments:
                        vae_encoder: the encoder object (VAEEncoder object)
                        vae_decoder: the decoder object (VAEDecoder object) 
                        mlp_model: the multi-layered perceptron object, trained on mus (PropertyRegressionModel object)
                        z_model: the multi-layered perceptron object, trained on zs (PropertyRegressionModel object)
                        encoding_alphabet: the alphabet generated by the function get_selfie_and_smiles_encodings_for_dataset (list)
                        largest_molecule_len: the maximum length of the molecule encodings (int)
                        lpoint_size: number of dimensions in a given latent vector, e.g., 64 for a 64D latent vector (int)
                        encoding_list: a list containing the SELFIES (list)
                        settings: dict of settings used (dict) '''


    lower_sigma = settings['data']['lower_sigma']
    upper_sigma = settings['data']['upper_sigma']
    z_num = settings['data']['z_num']

    condition = lambda y: ('['+y+']' in set(encoding_alphabet))
    threshold_condition = lambda z: z.item() == 0 if z.dim() == 0 else len(z) == 0

    time_takens = []
    time_0 = time.time()
    predicted_finish = 0
    num_through = 0
    


    eps = generate_normal_tensor(z_num, lpoint_size, lower_sigma, upper_sigma).detach()
    

    run_list = get_run_log_list(settings)
    smiles_index= max(run_list)
    if smiles_index !=0:
        smiles_index +=1
    print('Starting SMILES index:', smiles_index)



    while smiles_index < len(encoding_list):
        if smiles_index % 10 ==0 and smiles_index !=0:

            predicted_finish = (sum(time_takens) / num_through) * (len(encoding_list) - smiles_index)

            print(f'SMILES: {smiles_index}/{len(encoding_list)}, time taken: {time.time()-time_0}')
            print(f'Predicted time until completion: {predicted_finish / (60**2)} hours')

            
            time_takens.append(time.time()-time_0)
            time_0 = time.time()



        zs = gen_step(encoding_list, smiles_index, encoding_alphabet, largest_molecule_len, vae_encoder, z_num, eps)
        mus, sm_list = z_process_step(zs, encoding_alphabet, vae_decoder, vae_encoder)


        top_mols, mus = sanitisation_step(sm_list, mus, condition)
        if threshold_condition(mus):
            save_index(smiles_index, settings)
            smiles_index+=1
            continue


        morgan_fp, daylight_fp, m2v = gen_fingerprints_BF(top_mols, FP_size)


        predictions, ID1_indices, ID2_indices = gen_predictions_step(MLP_model, m2v, morgan_fp, daylight_fp, mus)
        if threshold_condition(ID2_indices):
            save_index(smiles_index, settings)
            smiles_index+=1
            continue

        save_CSVs_step(top_mols, predictions, ID1_indices, ID2_indices, smiles_index, settings)
        save_index(smiles_index, settings)

        smiles_index +=1
        num_through +=1





def main():

    settings = yaml.safe_load(open("bf_settings.yml", "r"))
    smiles_path = settings['data']['smiles_path']

    vae_encoder, vae_decoder, MLP_model, selfies_alphabet, largest_molecule_len, lpoint_size, FP_size = get_models(settings)
    encoding_list, _, _ = get_selfie_and_smiles_encodings_for_dataset(smiles_path)

    bf(vae_encoder, vae_decoder, MLP_model, selfies_alphabet, largest_molecule_len, lpoint_size, encoding_list, FP_size, settings)

if __name__ == "__main__":
    main()