'''
Less important/used functions used in the pipeline. Much more messy/redundant but used for convenience
'''


import os
import pandas as pd
import torch
import selfies as sf
import numpy as np

from rdkit import Chem
from rdkit.Chem import rdFingerprintGenerator
from rdkit.Chem import RDConfig
from rdkit.Chem import AllChem
import deepchem as dc
fpgen = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=4096)


import torch.nn as nn
from torch.nn.utils.rnn import pad_sequence


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def remove_unrecognized_symbols(smiles_list):

    '''Removes blank spaces from the SMILES encodings'''

    '''Arguments:
                    smiles_list: the list of SMILES encodings (list)'''
    
    '''Outputs:
                    cleaned_smiles: the cleaned SMILES encodings list (list)'''

    cleaned_smiles = [smiles.replace('\n', '') for smiles in smiles_list]

    return cleaned_smiles

def selfies_to_zs(encoding_list, encoding_alphabet, largest_molecule_len, vae_encoder):

    z_list = []
    vae_encoder.eval()


    data = selfies_to_one_hot(encoding_list, encoding_alphabet, largest_molecule_len)
    zs = torch.empty(0, dtype=torch.float32).to('cpu')


    batch_size = 1024 



    inp_flat_one_hot = data.flatten(start_dim=1)
    inp_flat_one_hot = inp_flat_one_hot.unsqueeze(0)


    num_batches_train = int(data.shape[0] / batch_size)
    if num_batches_train < data.shape[0] / batch_size:
        num_batches_train = num_batches_train + 1


    for batch_iteration in range(num_batches_train):

        start_idx = batch_iteration * batch_size
        stop_idx = (batch_iteration + 1) * batch_size
        sub_flat_ = inp_flat_one_hot.squeeze()
        if sub_flat_.dim() < 2:
            sub_flat_ = sub_flat_.unsqueeze(0)
        sub_flat = sub_flat_[start_idx: stop_idx].unsqueeze(0).to(device)

        zs_sub, _, _ = vae_encoder(sub_flat)
        z_list.append(zs_sub.to('cpu'))

    zs = torch.cat(z_list)

    return zs

def selfies_to_all(encoding_list, encoding_alphabet, largest_molecule_len, vae_encoder, lpoint_size):


    data = selfies_to_one_hot(encoding_list, encoding_alphabet, largest_molecule_len)
    mus = torch.empty(0, dtype=torch.float32).to('cpu')
    zs = torch.empty(0, dtype=torch.float32).to('cpu')
    log_vars = torch.empty(0, dtype=torch.float32).to('cpu')



    batch_size = 1024 



    inp_flat_one_hot = data.flatten(start_dim=1)
    inp_flat_one_hot = inp_flat_one_hot.unsqueeze(0)


    num_batches_train = int(data.shape[0] / batch_size)
    if num_batches_train < data.shape[0] / batch_size:
        num_batches_train = num_batches_train + 1

    vae_encoder.eval()
    z_list = []
    mu_list = []
    log_var_list = []

    for batch_iteration in range(num_batches_train):

        start_idx = batch_iteration * batch_size
        stop_idx = (batch_iteration + 1) * batch_size
        sub_flat_ = inp_flat_one_hot.squeeze()
        if sub_flat_.dim() < 2:
            sub_flat_ = sub_flat_.unsqueeze(0)
        sub_flat = sub_flat_[start_idx: stop_idx].unsqueeze(0).to(device)

        zs_sub, mus_sub, log_vars_sub = vae_encoder(sub_flat)

        mu_list.append(mus_sub.to('cpu'))
        z_list.append(zs_sub.to('cpu'))
        log_var_list.append(log_vars_sub.to('cpu'))

    mus = torch.cat(mu_list)
    zs = torch.cat(z_list)
    log_vars = torch.cat(log_var_list)
    
    vae_encoder.train()

    return zs, mus, log_vars



def stats(y_test, y_pred):

    '''Statistics function that gives you the mse, mae and r^2'''

    '''Arguments:
                    y_test: the true value of whatever property you're analysing (Pytorch float tensor)
                    y_pred: the prediction value of whatever property you're analysing (Pytorch float tensor)'''
    
    '''Outputs:
                    MSE: mean squared error (float)
                    MAE: mean absolute error (float)
                    r2: the r squared coefficient (float)'''

    ABS_DIF = torch.abs(y_pred - y_test)
    MAE = torch.mean(ABS_DIF)
    MSE = torch.mean((y_pred - y_test)*(y_pred - y_test))

    
    MRE = torch.mean(ABS_DIF/y_test)

    SSR = torch.sum((y_test-y_pred).pow(2))
    SST = torch.sum((y_test-y_test.mean()).pow(2))
    r2 = 1 - SSR/SST

    return MSE, MAE, MRE, r2

def selfies_to_one_hot(encoding_list, encoding_alphabet, largest_molecule_len):
    '''One hot generation'''

    '''Arguments:
                    encoding_list: a list containing the SELFIES (list)
                    encoding_alphabet: the alphabet generated by the function get_selfie_and_smiles_encodings_for_dataset (list)
                    largest_molecule_len: the maximum length of the molecule encodings (int)'''
    
    '''Outputs:
                    one_hot: pytorch tensor of representing the SELFIES contained within the encoding_list (Pytorch float.32 tensor) '''

    alphabet_dict = {letter: index for index, letter in enumerate(encoding_alphabet)}
    integer_encoded = [[alphabet_dict[symbol] for symbol in sf.split_selfies(encoding_list[x])] for x in range(len(encoding_list))]
    max_length = max(len(inner_list) for inner_list in integer_encoded)
    padded_list = [torch.tensor(inner_list + [0] * (max_length - len(inner_list))) for inner_list in integer_encoded]
    padded_tensor = pad_sequence(padded_list, batch_first=True, padding_value=0)

    if padded_tensor.shape[1] < largest_molecule_len:
        extra_padding = torch.zeros(padded_tensor.shape[0],(largest_molecule_len), dtype = torch.int64)
        extra_padding[:, :padded_tensor.shape[1]] = padded_tensor
        padded_tensor = extra_padding

    
    one_hot = torch.nn.functional.one_hot(padded_tensor, num_classes = len(encoding_alphabet)).to(torch.float32)


    return one_hot


def _make_dir(directory):

    '''Makes the directory'''

    '''Arguments:
                    directory: directory path (str)'''
    os.makedirs(directory)


def get_free_memory(device):

    '''Calculate the amount of free memory'''

    '''Arguments:
                    device: thr device being used (Pytorch object)'''
    
    '''Outputs:
                    free_mem: the amount of free memory in bytes (float)'''

    total_memory = torch.cuda.get_device_properties(device).total_memory
    reserved_memory = torch.cuda.memory_reserved(device)
    free_mem = total_memory - reserved_memory

    return free_mem

def get_free_ram():
    import psutil

    memory_info = psutil.virtual_memory()
    free_mem = memory_info.available
           
    return free_mem


def gen_properties_tensor(my_file):
    properties_df = my_file.drop(columns=['smiles'])
    properties_array = properties_df.to_numpy() 
    properties_tensor = torch.tensor(properties_array,dtype=torch.float32)

    return properties_tensor


def lpoints_to_onehots(zs, selfies_alphabet, vae_decoder):


    data_list = []
    big_data_list = []
    if zs.dim() <2:
        zs = zs.unsqueeze(0)
    zs = zs.to('cpu')

    batch_size = 128
    num_batches_train = int(len(zs) / batch_size)

    if num_batches_train < len(zs)/batch_size:
        num_batches_train = num_batches_train + 1

    for batch_iteration in range(num_batches_train):

        start_idx = batch_iteration * batch_size
        stop_idx = (batch_iteration + 1) * batch_size
        batch = zs[start_idx: stop_idx].to(device)

        with torch.no_grad():
            out_one_hot = vae_decoder(batch)
        seq_tensor = out_one_hot.argmax(2)
        
        data = torch.nn.functional.one_hot(seq_tensor, num_classes = len(selfies_alphabet)).to(torch.bool)
        data_list.append(data)

        if batch_iteration % 256 == 0:
            #free_mem = get_free_ram()
            #print('Batch iteration:', batch_iteration, '/', num_batches_train, 'free memory:', free_mem/(1024**3), 'GB')
            data = torch.cat(data_list).to('cpu')
            big_data_list.append(data)
            data_list = []

    one_hot_tensor = torch.cat(big_data_list).to(torch.float32)


    return one_hot_tensor


def onehots_to_lpoints(data, vae_encoder):

    mu_list = []
    mus = torch.empty(0, dtype=torch.float32)


    batch_size = 1024



    inp_flat_one_hot = data.flatten(start_dim=1)
    inp_flat_one_hot = inp_flat_one_hot.unsqueeze(0)


    num_batches_train = int(data.shape[0] / batch_size)
    if num_batches_train < data.shape[0] / batch_size:
        num_batches_train = num_batches_train + 1

    vae_encoder.eval()

    for batch_iteration in range(num_batches_train):

        start_idx = batch_iteration * batch_size
        stop_idx = (batch_iteration + 1) * batch_size
        sub_flat_ = inp_flat_one_hot.squeeze()
        if sub_flat_.dim() < 2:
            sub_flat_ = sub_flat_.unsqueeze(0)
        sub_flat = sub_flat_[start_idx: stop_idx].unsqueeze(0).to(device)

        _, mus_sub, _ = vae_encoder(sub_flat)
        mu_list.append(mus_sub)

    

    mus = torch.cat(mu_list)#.to(device)

    return mus

def onehots_to_zs(data, vae_encoder):

    z_list = []
    zs = torch.empty(0, dtype=torch.float32)


    batch_size = 1024



    inp_flat_one_hot = data.flatten(start_dim=1)
    inp_flat_one_hot = inp_flat_one_hot.unsqueeze(0)


    num_batches_train = int(data.shape[0] / batch_size)
    if num_batches_train < data.shape[0] / batch_size:
        num_batches_train = num_batches_train + 1

    vae_encoder.eval()

    for batch_iteration in range(num_batches_train):

        start_idx = batch_iteration * batch_size
        stop_idx = (batch_iteration + 1) * batch_size
        sub_flat_ = inp_flat_one_hot.squeeze()
        if sub_flat_.dim() < 2:
            sub_flat_ = sub_flat_.unsqueeze(0)
        sub_flat = sub_flat_[start_idx: stop_idx].unsqueeze(0)

        zs_sub, _, _ = vae_encoder(sub_flat)
        z_list.append(zs_sub)

    

    zs = torch.cat(z_list)#.to(device)

    return zs

def canonicalize_smiles(mol):
    if mol:
        return Chem.MolToSmiles(mol, canonical=True)
    else:
        return None  # In case the SMILES is invalid

def fp_generation(smiles_list):
    fp = []
    for i in range(len(smiles_list)):
        if i % 1000 ==0:
            print('fingerprint', i, 'processed')
        try:
            fp.append(fpgen.GetFingerprint(Chem.MolFromSmiles(smiles_list[i])).ToBitString())

        except:
            fp.append(0)

    return fp
        

def make_model(size_feature, width, activation, dropout, n_layers, l_rate, batch_size, loss_fn, size_target):
        #Define a pytorch model for use in deepchem 
        
        layers = []
        
        # Input layer
        layers.append(torch.nn.Linear(size_feature, width))
        layers.append(torch.nn.BatchNorm1d(width))
        layers.append(activation)
        layers.append(torch.nn.Dropout(dropout))
        
        # Hidden layers
        for _ in range(n_layers - 1):
                layers.append(torch.nn.Linear(width, width))
                layers.append(torch.nn.BatchNorm1d(width))
                layers.append(activation)
                layers.append(torch.nn.Dropout(dropout))
        
        # Output layer
        layers.append(torch.nn.Linear(width, size_target))
        
        # Create the sequential model    
        return dc.models.TorchModel(torch.nn.Sequential(*layers),loss_fn, learning_rate=dc.models.optimizers.ExponentialDecay(l_rate, 0.90, 300) ,batch_size=batch_size)

def threshold_refiner(selfies_list, prediction, condition, imp_props):
     
    mask = condition(prediction)
    threshold_indices = mask.squeeze().nonzero().squeeze().tolist()

    if type(threshold_indices) == int:
        threshold_indices = [threshold_indices]

    top_predictions = prediction[threshold_indices]
    imp_props = imp_props[threshold_indices]
    top_selfies = [selfies_list[x] for x in threshold_indices]

    if len(top_selfies) > 0:
        top_smiles = [sf.decoder(x) for x in top_selfies]
    else:
        top_smiles = []

    return top_selfies, top_smiles, top_predictions, imp_props


def try_encode(x):
    try:
        return sf.encoder(x)
    except Exception:
        return None
    

def get_run_log_list(settings):

    if os.path.exists(settings['data']['save_path'] + '/index_list.txt'):
        log_txt = pd.read_csv(settings['data']['save_path'] + '/index_list.txt')
        run_log_list = log_txt['log']
        run_log_list = run_log_list.astype(int)
        run_log_list = run_log_list.tolist() #.astype(int).tolist()
        
    else:
        run_log_list = [0]


    return run_log_list

def save_index(index, settings):


    save_path = settings['data']['save_path']
    log_filename = 'index_list.txt'

    log_filepath = os.path.join(save_path, log_filename)

    if not os.path.exists(save_path):
        os.makedirs(save_path)

    file_exists = os.path.isfile(log_filepath)

    with open(log_filepath, 'a') as file:
        if not file_exists:
            file.write("log\n")
        file.write(f'{index}\n')


def unique_values_and_first_indices(LIS):
    unique_values = []
    first_indices = []
    seen = {}

    for i, num in enumerate(LIS):
        if num not in seen:
            seen[num] = i
            unique_values.append(num)
            first_indices.append(i)
    
    return unique_values, first_indices

def non_none_values_and_indices(LIS):
    non_none_values = []
    non_none_indices = []

    for i, value in enumerate(LIS):
        if value is not None:
            non_none_values.append(value)
            non_none_indices.append(i)
    
    return non_none_values, non_none_indices


def generate_normal_tensor(z_num, lpoint_size, bottom, top):
    eps = torch.rand(z_num, lpoint_size)
    eps = eps * (top - bottom)
    eps = eps + bottom
    mask = (torch.rand_like(eps) > 0.5).detach()
    eps[mask] = -eps[mask].detach()
    
    return eps
